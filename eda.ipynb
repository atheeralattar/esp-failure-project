{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import missingno as msno\n",
    "from sklearn.impute import KNNImputer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = pd.read_csv('data/train_data/tracker.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combingin the\n",
    "directory = 'data/train_data/'\n",
    "\n",
    "# Initialize an empty dataframe\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Loop through files in the directory\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if (filename.startswith('z')):  # Assuming the files are in CSV format\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        # Read the file into a dataframe\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Add a column with the file name\n",
    "               \n",
    "        df = df.rename(columns={'Unnamed: 0': 'timestamp'})\n",
    "                \n",
    "        # Concatenate the dataframe to the combined dataframe\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], format='mixed')\n",
    "               \n",
    "        imputed_data = df.ffill().bfill()\n",
    "        \n",
    "        # Convert the result back to a DataFrame\n",
    "        imputed_df = pd.DataFrame(imputed_data, columns=df.columns)\n",
    "        imputed_df.set_index('timestamp', inplace=True)\n",
    "        imputed_df = imputed_df.resample('1h').mean()\n",
    "        \n",
    "        imputed_df['File Name'] = filename\n",
    "        \n",
    "        imputed_df.to_csv(f'data/train_data_imputed/{filename}', index=True)               \n",
    "        \n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "combined_df = combined_df.rename(columns={'Unnamed: 0': 'timestamp'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_test = pd.read_csv('data/train_data_imputed/z8jfojffxz.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_test['date'] = pd.to_datetime(df_clean_test['timestamp']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = pd.read_csv('data/train_data/tracker.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns with 'Date' in their name to date format\n",
    "date_columns = [col for col in df_clean_test.columns if 'Date' in col or 'date' in col]\n",
    "df_clean_test[date_columns] = df_clean_test[date_columns].apply(pd.to_datetime, format='%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_filtered = tracker[tracker['API'].isin(df_clean_test['File Name'].str[:-4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_162741/438238233.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tracker_filtered.sort_values(by='Install #', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "tracker_filtered.sort_values(by='Install #', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = tracker.sort_values(by=['API', 'Install #'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = [col for col in tracker.columns if 'Date' in col or 'date' in col]\n",
    "# Convert date columns to datetime, original format is 3/3/2023 0:00, target format is %Y-%m-%d \n",
    "for col in date_cols:\n",
    "    tracker[col] = pd.to_datetime(tracker[col], format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.read_csv('data/train_data/combined_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(combined_df, figsize=(20, 10), fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['timestamp'] = pd.to_datetime(combined_df['timestamp'], format='mixed')\n",
    "combined_df['day'] = combined_df['timestamp'].dt.day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 205 entries, 0 to 204\n",
      "Series name: Startup Date\n",
      "Non-Null Count  Dtype         \n",
      "--------------  -----         \n",
      "53 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](1)\n",
      "memory usage: 3.2 KB\n"
     ]
    }
   ],
   "source": [
    "tracker['Startup Date'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = (nan_counts / len(combined_df)) * 100\n",
    "#print(percentage)\n",
    "#print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing for downsampling\n",
    "combined_df.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "\n",
    "# Fit and transform the DataFrame\n",
    "imputed_data = imputer.fit_transform()\n",
    "\n",
    "# Convert the result back to a DataFrame\n",
    "imputed_df = pd.DataFrame(imputed_data, columns=df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.resample('1D').mean().interpolate(method='linear', limit_direction='both', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker['startup_date'] = pd.to_datetime(tracker['Startup Date'], format='%m/%d/%Y').dt.date\n",
    "tracker['failure_date'] = pd.to_datetime(tracker['Corrected Failure Date'], format='%m/%d/%Y').dt.date\n",
    "tracker['pull_date'] = pd.to_datetime(tracker['Pull date'], format='%m/%d/%Y').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.to_csv('data/train_data/tracker_date_corrected.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'data/train_data_imputed/'\n",
    "\n",
    "# Initialize an empty dataframe\n",
    "combined_df_imputed = pd.DataFrame()\n",
    "\n",
    "# Loop through files in the directory\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if (filename.startswith('z')):  # Assuming the files are in CSV format\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        combined_df_imputed = pd.concat([combined_df_imputed, df], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_imputed.to_csv('data/train_data_imputed/combined_data_imputed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_imputed['timestamp'] = pd.to_datetime(combined_df_imputed['timestamp'])\n",
    "combined_df_imputed['timestamp'] = combined_df_imputed['timestamp'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp                object\n",
       "pump_intake_pressure    float64\n",
       "motor_frequency         float64\n",
       "motor_temp              float64\n",
       "pump_intake_temp        float64\n",
       "x_vibration             float64\n",
       "y_vibration             float64\n",
       "motor_amps_phase_b      float64\n",
       "output_amps_phase_b     float64\n",
       "casing_pressure         float64\n",
       "tubing_pressure         float64\n",
       "gas_rate                float64\n",
       "oil_rate                float64\n",
       "water_rate              float64\n",
       "File Name                object\n",
       "status                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_imputed.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_245354/1032786091.py:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'failure' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  combined_df_imputed.loc[(combined_df_imputed['File Name'] == well) &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "well z8j7xj31j7 has a failure on 2023-10-08\n",
      "well z8j7xjz3z3 has a failure on 2021-05-21\n",
      "well z8j7xjz3z3 has a failure on 2022-05-06\n",
      "well z8j7xjz78f has a failure on 2022-01-01\n",
      "well z8j7xjz78f has a failure on 2023-08-14\n",
      "well z8jfoj1ef3 has a failure on 2021-12-05\n",
      "well z8jfoj1ef3 has a failure on 2022-07-08\n",
      "well z8jfoj1ef3 has a failure on 2023-08-10\n",
      "well z8jfoj1efe has a failure on 2021-06-15\n",
      "well z8jfoj1efe has a failure on 2023-09-29\n",
      "well z8jfoj1o7f has a failure on 2021-07-22\n",
      "well z8jfoj1o7f has a failure on 2021-09-04\n",
      "well z8jfoj1o7f has a failure on 2023-02-28\n",
      "well z8jfoj1z3o has a failure on 2023-03-02\n",
      "well z8jfoje1jf has a failure on 2022-04-04\n",
      "well z8jfoje1jf has a failure on 2023-02-14\n",
      "well z8jfoje1o1 has a failure on 2022-07-13\n",
      "well z8jfoje1o1 has a failure on 2022-07-01\n",
      "well z8jfoje1o1 has a failure on 2023-04-01\n",
      "well z8jfoje87x has a failure on 2022-08-30\n",
      "well z8jfoje87x has a failure on 2022-12-20\n",
      "well z8jfojee13 has a failure on 2021-11-10\n",
      "well z8jfojeefx has a failure on 2021-12-27\n",
      "well z8jfojeefx has a failure on 2023-06-11\n",
      "well z8jfojeox8 has a failure on 2021-12-13\n",
      "well z8jfojexz3 has a failure on 2022-03-12\n",
      "well z8jfojexz3 has a failure on 2023-05-20\n",
      "well z8jfojexz8 has a failure on 2021-10-21\n",
      "well z8jfojexz8 has a failure on 2023-01-23\n",
      "well z8jfojexzx has a failure on 2023-01-08\n",
      "well z8jfojf177 has a failure on 2023-06-08\n",
      "well z8jfojf177 has a failure on 2023-12-26\n",
      "well z8jfojf313 has a failure on 2021-06-23\n",
      "well z8jfojf313 has a failure on 2022-02-25\n",
      "well z8jfojf313 has a failure on 2022-09-23\n",
      "well z8jfojf313 has a failure on 2023-07-08\n",
      "well z8jfojf313 has a failure on 2023-09-27\n",
      "well z8jfojf318 has a failure on 2021-07-07\n",
      "well z8jfojf318 has a failure on 2022-09-04\n",
      "well z8jfojf31j has a failure on 2023-03-13\n",
      "well z8jfojf373 has a failure on 2021-07-18\n",
      "well z8jfojf373 has a failure on 2023-02-16\n",
      "well z8jfojf37f has a failure on 2022-12-11\n",
      "well z8jfojf37f has a failure on 2023-08-23\n",
      "well z8jfojf37o has a failure on 2021-05-16\n",
      "well z8jfojf37o has a failure on 2021-11-08\n",
      "well z8jfojf37o has a failure on 2022-03-11\n",
      "well z8jfojf37o has a failure on 2023-02-14\n",
      "well z8jfojf37z has a failure on 2021-06-27\n",
      "well z8jfojf37z has a failure on 2021-10-06\n",
      "well z8jfojf73z has a failure on 2022-11-19\n",
      "well z8jfojf7ff has a failure on 2021-06-28\n",
      "well z8jfojf7ff has a failure on 2022-12-20\n",
      "well z8jfojf7xo has a failure on 2022-03-01\n",
      "well z8jfojf7xo has a failure on 2023-02-27\n",
      "well z8jfojf833 has a failure on 2022-09-16\n",
      "well z8jfojf833 has a failure on 2023-05-11\n",
      "well z8jfojf833 has a failure on 2024-01-05\n",
      "well z8jfojfejo has a failure on 2021-09-01\n",
      "well z8jfojfejo has a failure on 2022-04-25\n",
      "well z8jfojffx7 has a failure on 2022-05-18\n",
      "well z8jfojffx7 has a failure on 2023-11-01\n",
      "well z8jfojffxz has a failure on 2021-11-28\n",
      "well z8jfojffxz has a failure on 2022-09-06\n",
      "well z8jfojffxz has a failure on 2023-09-30\n",
      "well z8jfojfj17 has a failure on 2021-10-06\n",
      "well z8jfojfj1z has a failure on 2021-03-12\n",
      "well z8jfojfj1z has a failure on 2022-09-03\n",
      "well z8jfojfj1z has a failure on 2023-12-23\n",
      "well z8jfojfo71 has a failure on 2023-03-31\n",
      "well z8jfojfo7f has a failure on 2023-06-13\n",
      "well z8jfojfo7f has a failure on 2024-01-07\n",
      "well z8jfojfo7j has a failure on 2022-01-30\n",
      "well z8jfojfo7j has a failure on 2022-07-26\n",
      "well z8jfojfo7j has a failure on 2023-01-05\n",
      "well z8jfojfox8 has a failure on 2023-02-24\n",
      "well z8jfojfox8 has a failure on 2023-05-08\n",
      "well z8jfojfoxx has a failure on 2023-07-30\n",
      "well z8jfojfxoe has a failure on 2021-10-27\n",
      "well z8jfojfxoe has a failure on 2023-05-21\n",
      "well z8jfojfze1 has a failure on 2022-01-19\n",
      "well z8jfojfze1 has a failure on 2022-11-18\n",
      "well z8jfojfzz3 has a failure on 2021-12-16\n",
      "well z8jfojfzz3 has a failure on 2023-08-23\n",
      "well z8jfojfzz3 has a failure on 2023-12-16\n",
      "well z8jfojjfjx has a failure on 2021-07-11\n",
      "well z8jfojjfjx has a failure on 2023-07-08\n",
      "well z8jfojo31x has a failure on 2022-10-09\n",
      "well z8jfojo31x has a failure on 2023-02-19\n",
      "well z8jfojo31x has a failure on 2023-09-07\n",
      "well z8jfojo3j7 has a failure on 2023-04-28\n",
      "well z8jfojo3j8 has a failure on 2023-03-26\n",
      "well z8jfojo3zf has a failure on 2022-12-08\n",
      "well z8jfojo3zf has a failure on 2023-12-23\n",
      "well z8jfojo3zo has a failure on 2022-11-11\n",
      "well z8jfojo3zo has a failure on 2023-03-09\n",
      "well z8jfojo3zo has a failure on 2023-06-23\n",
      "well z8jfojo71z has a failure on 2022-10-07\n",
      "well z8jfojo7e1 has a failure on 2021-11-14\n",
      "well z8jfojo7e1 has a failure on 2022-03-25\n",
      "well z8jfojo7e1 has a failure on 2023-05-23\n",
      "well z8jfojo7jf has a failure on 2022-03-22\n",
      "well z8jfojo7jf has a failure on 2023-12-02\n",
      "well z8jfojo83x has a failure on 2022-09-16\n",
      "well z8jfojo83x has a failure on 2024-01-04\n",
      "well z8jfojo83x has a failure on 2024-01-04\n",
      "well z8jfojo88j has a failure on 2023-02-15\n",
      "well z8jfojo88j has a failure on 2023-12-06\n",
      "well z8jfojoe11 has a failure on 2023-03-23\n",
      "well z8jfojoe11 has a failure on 2023-10-01\n",
      "well z8jfojoe13 has a failure on 2023-01-29\n",
      "well z8jfojoe1f has a failure on 2022-12-23\n",
      "well z8jfojoe1f has a failure on 2023-05-07\n",
      "well z8jfojoe1o has a failure on 2023-06-17\n",
      "well z8jfojoeeo has a failure on 2023-06-24\n",
      "well z8jfojoeeo has a failure on 2023-07-04\n",
      "well z8jfojoefx has a failure on 2023-02-11\n",
      "well z8jfojoefx has a failure on 2023-08-26\n",
      "well z8jfojoefx has a failure on 2023-12-01\n",
      "well z8jfojojf8 has a failure on 2023-02-20\n",
      "well z8jfojox8z has a failure on 2022-07-22\n",
      "well z8jfojox8z has a failure on 2023-01-09\n",
      "well z8jfojox8z has a failure on 2023-03-01\n",
      "well z8jfojox8z has a failure on 2023-11-17\n",
      "well z8jfojoxzx has a failure on 2023-02-26\n",
      "well z8jfojoz8o has a failure on 2023-08-15\n",
      "well z8jfojozxj has a failure on 2022-10-31\n",
      "well z8jfojozxj has a failure on 2023-10-12\n",
      "well z8jfojozxx has a failure on 2022-10-20\n",
      "well z8jfojozxx has a failure on 2023-03-29\n",
      "well z8jfojzf7j has a failure on 2022-02-12\n",
      "well z8x7ojjefj has a failure on 2023-01-17\n",
      "well z8x7ojjefj has a failure on 2023-09-26\n",
      "well z8x7ojjex3 has a failure on 2022-05-03\n",
      "well z8x7ojjex3 has a failure on 2022-06-19\n",
      "well z8x7ojjex3 has a failure on 2023-04-26\n",
      "well z8x7ojjexz has a failure on 2021-12-28\n",
      "well z8x7ojjexz has a failure on 2022-08-15\n",
      "well z8x7ojjexz has a failure on 2023-09-17\n",
      "well z8x7ojjje8 has a failure on 2023-01-14\n",
      "well z8x7ojjje8 has a failure on 2023-10-03\n",
      "well z8x7ojjje8 has a failure on 2023-12-12\n",
      "well z8x7ojjxf7 has a failure on 2021-06-16\n",
      "well z8x7ojjxf7 has a failure on 2021-07-30\n",
      "well z8x7ojjxf7 has a failure on 2022-11-21\n"
     ]
    }
   ],
   "source": [
    "unique_wells = tracker['API'].unique()\n",
    "\n",
    "for well in unique_wells:\n",
    "    \n",
    "    # preparing comparison dfs    \n",
    "    #df_temp = combined_df_imputed[combined_df_imputed['File Name'] == well]\n",
    "    combined_df_imputed['timestamp']  = pd.to_datetime(combined_df_imputed['timestamp'])\n",
    "    combined_df_imputed['timestamp'] = combined_df_imputed['timestamp'].dt.date\n",
    "    tracker_temp = tracker[tracker['API'] == well]\n",
    "    \n",
    "    for date in tracker_temp['failure_date']:\n",
    "        # Check if the date is in the DataFrame\n",
    "        if date in combined_df_imputed[combined_df_imputed['File Name'] == well]['timestamp'].values:\n",
    "            # Update the status column for that date\n",
    "            combined_df_imputed.loc[(combined_df_imputed['File Name'] == well) & \n",
    "                                    (combined_df_imputed['timestamp'] == date), 'status'] = 'failure'\n",
    "            print(f'well {well} has a failure on {date}')            \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_imputed.to_csv('data/train_data_imputed/combined_data_imputed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.loc[:, 'timestamp'] = pd.to_datetime(df_temp['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Install #', 'Link', 'API', 'Ins Date', 'Startup Date', 'Pull date',\n",
       "       'Corrected Failure Date', 'Status', 'PSD (ft)', 'Stage Count',\n",
       "       'Producer', 'Pump Producer Model', 'Gas Handling', 'GasSep/Int',\n",
       "       'Motor', 'PMM or IM', 'DHG', 'MLE', 'CABLE', 'Cable Status',\n",
       "       'Cap string', 'Injection Location', 'Desander', 'Joints Filled',\n",
       "       'Gas Tools', 'Anode/Tubing', 'Clamps', 'Sand Fallback', 'Casing Size',\n",
       "       'Casing Weight', 'TBG SIZE', 'Failure Y/N', 'Reason for pulling',\n",
       "       'Component Failed', 'Sub Category', 'Fail reason', 'Comments',\n",
       "       'Install Notes', 'T2P', 'Pull Notes', 'Exception', 'Teardown Status',\n",
       "       'Teardown Schedule', 'Report', 'Time to Report', 'Oil', 'Water', 'Gas',\n",
       "       'Total Production', 'Pump Intake', 'Free Gas', 'Range',\n",
       "       'Actual Run Time', 'Percent Uptime', 'Number of Shutdowns',\n",
       "       'Reason for Pull: General', 'Reason for Pull: Specific',\n",
       "       'Primary Failed Component', 'Primary Failure Subcomponent',\n",
       "       'Primary Failure Category', 'Specific Failure Mechanism',\n",
       "       'Failure Cause: General', 'Failure Cause: Specific',\n",
       "       'Max  - Total Fluid', 'Average - Total Fluid',\n",
       "       'Chemical Injection Method', 'Pump Status', 'Gas Sep Status',\n",
       "       'Motor Status', 'Sensor Status', 'Pump Savings', 'Motor Savings',\n",
       "       'Other Savings', 'Cable Savings', 'Deviation From Full System',\n",
       "       'Total Savings', 'Cable Quote', 'Downhole Quote', 'startup_date',\n",
       "       'failure_date', 'pull_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp                object\n",
       "pump_intake_pressure    float64\n",
       "motor_frequency         float64\n",
       "motor_temp              float64\n",
       "pump_intake_temp        float64\n",
       "x_vibration             float64\n",
       "y_vibration             float64\n",
       "motor_amps_phase_b      float64\n",
       "output_amps_phase_b     float64\n",
       "casing_pressure         float64\n",
       "tubing_pressure         float64\n",
       "gas_rate                float64\n",
       "oil_rate                float64\n",
       "water_rate              float64\n",
       "File Name                object\n",
       "status                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
